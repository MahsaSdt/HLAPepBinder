{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HLAPepBinder Testing Code\n",
        "\n",
        "This project provides the test steps for the HLAPepBinder model, which is designed to predict HLA-peptide binding. The test script loads pre-trained models, predicts binding scores for given peptide and HLA pairs, and evaluates the performance of both the base models and HLAPepBinder.\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. **Loading Test Data**: The code first loads a test dataset containing pairs of peptides and HLA sequences. Each pair will be processed to gather binding predictions from multiple baseline models.\n",
        "\n",
        "2. **Loading the Pre-trained Model**: The pre-trained HLAPepBinder model is then loaded to predict HLA-peptide binding based on the scores from base models.\n",
        "\n",
        "3. **Generating Base Model Predictions**: For each peptide-HLA pair, the code retrieves scores from nine baseline models that are available in http://tools.iedb.org/mhci/ . These scores are essential inputs for HLAPepBinder and must be organized respectily as follows:\n",
        "\n",
        "   - **Ann**: IC50 value\n",
        "   - **Consensus**: Percentile value\n",
        "   - **NetMHCpan_BA**: IC50 value\n",
        "   - **NetMHCpan_EL**: Score value\n",
        "   - **SMM**: IC50 value\n",
        "   - **SMMPMBEC**: IC50 value\n",
        "   - **PickPocket**: IC50 value\n",
        "   - **NetMHCcons**: IC50 value\n",
        "   - **NetMHCStabPan**: Score value\n",
        "\n",
        "   These values should be stored for each peptide-HLA pair, creating a feature vector for prediction.\n",
        "\n",
        "4. **Predicting with HLAPepBinder**: Once the input data is prepared, the HLAPepBinder model is used to predict the binding outcomes for the test set.\n",
        "\n",
        "5. **Evaluating the Model**: The script then calculates evaluation metrics for each of the base models as well as HLAPepBinder. Key metrics include accuracy, precision, recall, and F1-score, offering a comparison between the base models and HLAPepBinder.\n",
        "\n",
        "\n",
        "## Notes\n",
        "\n",
        "- Ensure the test data format aligns with the expected input structure.\n",
        "- Model predictions depend on accurate scoring from each base model, so check that all input values are properly formatted and scaled as specified.\n"
      ],
      "metadata": {
        "id": "2jVDSI-GAoKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UUZ3cSXEAupq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score,precision_score,recall_score\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib"
      ],
      "metadata": {
        "id": "37o1a1HG8fBW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BasePred(X_test,y_test):\n",
        "  #thresholds and base models performance\n",
        "  label = [[0, 1][i <= 500] for i in X_test['ann']]\n",
        "  print(\"*Ann*\\nAcc: \",accuracy_score(label,y_test))\n",
        "  print('Recall:',recall_score(y_test, label))\n",
        "  print('Percision:',precision_score(y_test, label))\n",
        "  print('F1:',f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][r <= 2] for r in X_test['consensus']]\n",
        "  print(\"*consensus*\\nAcc: \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][i <= 500] for i in X_test['netmhcpan_ba']]\n",
        "  print(\"*netmhcpan_ba*\\nAcc:  \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][score >= 0.5] for score in X_test['netmhcpan_el']]\n",
        "  print(\"*netmhcpan_el*\\nAcc:  \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][i <= 500] for i in X_test['smm']]\n",
        "  print(\"*smm*\\nAcc:  \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][i <= 500] for i in X_test['smmpmbec']]\n",
        "  print(\"*smmpmbec*\\nAcc:  \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][i <= 500] for i in X_test['pickpocket']]\n",
        "  print(\"*pickpocket*\\nAcc:  \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][i <= 500] for i in X_test['netmhccons']]\n",
        "  print(\"*netmhccons*\\nAcc:  \",accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')\n",
        "  label = [[0, 1][score >= 0.5] for score in X_test['netmhcstabpan']]\n",
        "  print(\"*netmhcstabpan*\\nAcc:  \", accuracy_score(label,y_test))\n",
        "  print('Recall:', recall_score(y_test, label))\n",
        "  print('Percision:', precision_score(y_test, label))\n",
        "  print('F1:', f1_score(y_test, label))\n",
        "  print('------------------------------------------')"
      ],
      "metadata": {
        "id": "li_I8neP_R53"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Main dataset performence"
      ],
      "metadata": {
        "id": "GXNODpA4_JVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/data/test.csv')\n",
        "y_test = test['label']\n",
        "X_test = test.drop(columns=['label','peptide','HLA'])"
      ],
      "metadata": {
        "id": "0NC2fxJs8fAO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the  model\n",
        "clf = joblib.load('HLAPepBinder.joblib')\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"*HLAPepBinder*\\nAcc: \",accuracy_score(y_pred,y_test))\n",
        "print('Recall:',recall_score(y_test, y_pred))\n",
        "print('Percision:',precision_score(y_test, y_pred))\n",
        "print('F1:',f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33w5W-L97ZDm",
        "outputId": "7c3e940f-56bf-4ba5-8fe4-d74339577f7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*HLAPepBinder*\n",
            "Acc:  0.9161180098341528\n",
            "Recall: 0.9017161992465467\n",
            "Percision: 0.9277347114556417\n",
            "F1: 0.914540437274464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BasePred(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7vPlvBy9IE_",
        "outputId": "ca0f77e5-f318-439a-f34a-c6b9d26c5cd6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*Ann*\n",
            "Acc:  0.7431035919659972\n",
            "Recall: 0.4956885726245291\n",
            "Percision: 0.9767403497195645\n",
            "F1: 0.6576331426667407\n",
            "------------------------------------------\n",
            "*consensus*\n",
            "Acc:  0.7398116509709143\n",
            "Recall: 0.48974466303892844\n",
            "Percision: 0.975162527087848\n",
            "F1: 0.652028533214445\n",
            "------------------------------------------\n",
            "*netmhcpan_ba*\n",
            "Acc:   0.7481873489457455\n",
            "Recall: 0.5031393888656341\n",
            "Percision: 0.9823471722785224\n",
            "F1: 0.66544870730222\n",
            "------------------------------------------\n",
            "*netmhcpan_el*\n",
            "Acc:   0.750312526043837\n",
            "Recall: 0.5025533696107157\n",
            "Percision: 0.9917396332397158\n",
            "F1: 0.6670741193465941\n",
            "------------------------------------------\n",
            "*smm*\n",
            "Acc:   0.7243936994749562\n",
            "Recall: 0.4697362913352867\n",
            "Percision: 0.9524698692921405\n",
            "F1: 0.6291769455034761\n",
            "------------------------------------------\n",
            "*smmpmbec*\n",
            "Acc:   0.7098924910409201\n",
            "Recall: 0.43507743825868567\n",
            "Percision: 0.960450933284051\n",
            "F1: 0.5988707075362987\n",
            "------------------------------------------\n",
            "*pickpocket*\n",
            "Acc:   0.6168847403950329\n",
            "Recall: 0.23884470489744664\n",
            "Percision: 0.965482233502538\n",
            "F1: 0.38295302013422816\n",
            "------------------------------------------\n",
            "*netmhccons*\n",
            "Acc:   0.7451037586465539\n",
            "Recall: 0.49619087484303054\n",
            "Percision: 0.9835711915034849\n",
            "F1: 0.6596182738857047\n",
            "------------------------------------------\n",
            "*netmhcstabpan*\n",
            "Acc:   0.7080173347778982\n",
            "Recall: 0.4367517789870239\n",
            "Percision: 0.949235807860262\n",
            "F1: 0.59824551344533\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##External dataset performance"
      ],
      "metadata": {
        "id": "i9hPL8_R_Ty9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXternal_test = pd.read_csv('/data/external_test.csv')\n",
        "y_test = EXternal_test['label']\n",
        "X_test = EXternal_test.drop(columns=['label','peptide','HLA'])"
      ],
      "metadata": {
        "id": "M14znBl6-vQ4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = joblib.load('HLAPepBinder.joblib')\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"*HLAPepBinder*\\nAcc: \",accuracy_score(y_pred,y_test))\n",
        "print('Recall:',recall_score(y_test, y_pred))\n",
        "print('Percision:',precision_score(y_test, y_pred))\n",
        "print('F1:',f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPBuyppK_dwJ",
        "outputId": "06a786e4-29ef-4feb-a12f-b45fc866a911"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*HLAPepBinder*\n",
            "Acc:  0.8963270807592946\n",
            "Recall: 0.8843302878813998\n",
            "Percision: 0.9531772575250836\n",
            "F1: 0.917464007869087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BasePred(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsxyw5sN_g07",
        "outputId": "6a581eb6-14ac-4a60-89bb-33dc57f20afa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*Ann*\n",
            "Acc:  0.7906323711108615\n",
            "Recall: 0.6864333735562834\n",
            "Percision: 0.9888254283585796\n",
            "F1: 0.8103378103378104\n",
            "------------------------------------------\n",
            "*consensus*\n",
            "Acc:  0.7363809951701673\n",
            "Recall: 0.6023099465609377\n",
            "Percision: 0.9886813808715337\n",
            "F1: 0.748580610605249\n",
            "------------------------------------------\n",
            "*netmhcpan_ba*\n",
            "Acc:   0.794114343479726\n",
            "Recall: 0.6922944319944837\n",
            "Percision: 0.9881889763779528\n",
            "F1: 0.8141915864166245\n",
            "------------------------------------------\n",
            "*netmhcpan_el*\n",
            "Acc:   0.7376165337526677\n",
            "Recall: 0.6011032580589554\n",
            "Percision: 0.9937304075235109\n",
            "F1: 0.7490870032223416\n",
            "------------------------------------------\n",
            "*smm*\n",
            "Acc:   0.7726609008199483\n",
            "Recall: 0.6609205309429409\n",
            "Percision: 0.9853508095605242\n",
            "F1: 0.7911679735864631\n",
            "------------------------------------------\n",
            "*smmpmbec*\n",
            "Acc:   0.7689542850724475\n",
            "Recall: 0.6540251680744699\n",
            "Percision: 0.9869927159209158\n",
            "F1: 0.7867288750648004\n",
            "------------------------------------------\n",
            "*pickpocket*\n",
            "Acc:   0.7612040885094912\n",
            "Recall: 0.6535080158593346\n",
            "Percision: 0.9703097005374968\n",
            "F1: 0.7810053564070869\n",
            "------------------------------------------\n",
            "*netmhccons*\n",
            "Acc:   0.8015275749747276\n",
            "Recall: 0.7036717807274607\n",
            "Percision: 0.9883777239709443\n",
            "F1: 0.8220722988621488\n",
            "------------------------------------------\n",
            "*netmhcstabpan*\n",
            "Acc:   0.854318768954285\n",
            "Recall: 0.799517324599207\n",
            "Percision: 0.9719195305951384\n",
            "F1: 0.8773290456823986\n",
            "------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}